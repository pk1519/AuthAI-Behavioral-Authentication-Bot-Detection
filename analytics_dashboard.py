"""
Comprehensive Analytics Dashboard for AuthAI Detection System

Features:
- Real-time performance metrics
- Model comparison and analysis
- Simulation effectiveness tracking
- Detection pattern analysis
- Comprehensive reporting
- Data visualization and insights
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import json
import os
from typing import Dict, List, Any, Optional
from collections import defaultdict

# Import our detection feedback system
try:
    from detection_feedback_system import create_detection_feedback_system
    from enhanced_behavior_simulator import SimulatorMode
except ImportError:
    st.error("Analytics dashboard requires detection_feedback_system.py and enhanced_behavior_simulator.py")
    st.stop()

class AnalyticsDashboard:
    """Main analytics dashboard for AuthAI system"""
    
    def __init__(self, detection_log_file: str = 'enhanced_detections_log.csv'):
        self.detection_log_file = detection_log_file
        self.feedback_system = create_detection_feedback_system(detection_log_file)
    
    def load_detection_data(self, days: int = 30) -> pd.DataFrame:
        """Load detection data for analysis"""
        try:
            if os.path.exists(self.detection_log_file):
                df = pd.read_csv(self.detection_log_file)
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                
                # Filter by date range
                cutoff_date = datetime.now() - timedelta(days=days)
                recent_df = df[df['timestamp'] >= cutoff_date]
                
                return recent_df
            else:
                return pd.DataFrame()
        except Exception as e:
            st.error(f"Error loading detection data: {e}")
            return pd.DataFrame()
    
    def create_overview_metrics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """Create overview metrics for the dashboard"""
        if df.empty:
            return {
                'total_events': 0,
                'bot_detections': 0,
                'detection_rate': 0,
                'avg_confidence': 0,
                'unique_users': 0,
                'simulation_events': 0
            }
        
        metrics = {
            'total_events': len(df),
            'bot_detections': len(df[df['is_bot_detected'] == True]),
            'detection_rate': len(df[df['is_bot_detected'] == True]) / len(df) * 100,
            'avg_confidence': df['confidence_score'].mean(),
            'unique_users': df['user_id'].nunique(),
            'simulation_events': len(df[df['source_type'] == 'simulation']),
            'real_user_events': len(df[df['source_type'] == 'real_user']),
            'dataset_replay_events': len(df[df['source_type'] == 'dataset_replay'])
        }
        
        return metrics
    
    def create_detection_timeline_chart(self, df: pd.DataFrame) -> go.Figure:
        """Create detection timeline visualization"""
        if df.empty:
            return None
        
        # Group by hour for timeline
        df['hour'] = df['timestamp'].dt.floor('H')
        timeline_data = df.groupby(['hour', 'source_type']).agg({
            'is_bot_detected': ['count', 'sum'],
            'confidence_score': 'mean'
        }).reset_index()
        
        # Flatten column names
        timeline_data.columns = ['hour', 'source_type', 'total_events', 'detections', 'avg_confidence']
        timeline_data['detection_rate'] = timeline_data['detections'] / timeline_data['total_events'] * 100
        
        fig = go.Figure()
        
        # Add traces for each source type
        for source_type in timeline_data['source_type'].unique():
            source_data = timeline_data[timeline_data['source_type'] == source_type]
            
            color_map = {
                'real_user': '#2ecc71',
                'simulation': '#e74c3c', 
                'dataset_replay': '#f39c12'
            }
            
            fig.add_trace(go.Scatter(\n                x=source_data['hour'],\n                y=source_data['detection_rate'],\n                mode='lines+markers',\n                name=f'{source_type.replace(\"_\", \" \").title()}',\n                line=dict(color=color_map.get(source_type, '#3498db'), width=2),\n                marker=dict(size=8),\n                hovertemplate=f'<b>{source_type}</b><br>Detection Rate: %{{y:.1f}}%<br>Hour: %{{x}}<extra></extra>'\n            ))\n        \n        fig.update_layout(\n            title=\"Detection Rate Over Time by Source Type\",\n            xaxis_title=\"Time\",\n            yaxis_title=\"Detection Rate (%)\",\n            height=400,\n            showlegend=True,\n            hovermode='x unified'\n        )\n        \n        return fig\n    \n    def create_model_performance_chart(self, df: pd.DataFrame) -> go.Figure:\n        """Create model performance comparison chart\"\"\"\n        if df.empty:\n            return None\n        \n        # Calculate performance by model\n        model_stats = df.groupby('model_used').agg({\n            'is_bot_detected': ['count', 'sum'],\n            'confidence_score': 'mean'\n        }).reset_index()\n        \n        model_stats.columns = ['model', 'total_events', 'detections', 'avg_confidence']\n        model_stats['detection_rate'] = model_stats['detections'] / model_stats['total_events'] * 100\n        \n        fig = go.Figure()\n        \n        # Detection rate bars\n        fig.add_trace(go.Bar(\n            x=model_stats['model'],\n            y=model_stats['detection_rate'],\n            name='Detection Rate (%)',\n            marker_color='#e74c3c',\n            text=model_stats['detection_rate'].round(1),\n            textposition='auto'\n        ))\n        \n        fig.update_layout(\n            title=\"Model Performance Comparison\",\n            xaxis_title=\"Model\",\n            yaxis_title=\"Detection Rate (%)\",\n            height=400,\n            showlegend=False\n        )\n        \n        return fig\n    \n    def create_profile_analysis_chart(self, df: pd.DataFrame) -> go.Figure:\n        \"\"\"Create behavior profile analysis chart\"\"\"\n        sim_df = df[df['source_type'] == 'simulation']\n        \n        if sim_df.empty:\n            return None\n        \n        # Calculate stats by profile\n        profile_stats = sim_df.groupby('simulation_profile').agg({\n            'is_bot_detected': ['count', 'sum'],\n            'confidence_score': 'mean'\n        }).reset_index()\n        \n        profile_stats.columns = ['profile', 'total_events', 'detections', 'avg_confidence']\n        profile_stats['detection_rate'] = profile_stats['detections'] / profile_stats['total_events'] * 100\n        \n        # Create scatter plot\n        fig = go.Figure()\n        \n        fig.add_trace(go.Scatter(\n            x=profile_stats['avg_confidence'],\n            y=profile_stats['detection_rate'],\n            mode='markers+text',\n            text=profile_stats['profile'],\n            textposition='top center',\n            marker=dict(\n                size=profile_stats['total_events'] * 2,  # Size by number of events\n                color=profile_stats['detection_rate'],\n                colorscale='RdYlBu_r',\n                colorbar=dict(title=\"Detection Rate (%)\"),\n                opacity=0.7\n            ),\n            hovertemplate='<b>%{text}</b><br>Avg Confidence: %{x:.3f}<br>Detection Rate: %{y:.1f}%<br>Events: %{marker.size}<extra></extra>'\n        ))\n        \n        fig.update_layout(\n            title=\"Behavior Profile Analysis\",\n            xaxis_title=\"Average Confidence Score\",\n            yaxis_title=\"Detection Rate (%)\",\n            height=500\n        )\n        \n        return fig\n    \n    def create_feature_correlation_matrix(self, df: pd.DataFrame) -> go.Figure:\n        \"\"\"Create feature correlation matrix\"\"\"\n        if df.empty:\n            return None\n        \n        feature_cols = [\n            'avg_mouse_speed', 'avg_typing_speed', 'tab_switch_rate',\n            'mouse_click_rate', 'keyboard_error_rate', 'active_window_duration',\n            'confidence_score'\n        ]\n        \n        # Filter to available columns\n        available_cols = [col for col in feature_cols if col in df.columns]\n        \n        if len(available_cols) < 2:\n            return None\n        \n        correlation_matrix = df[available_cols].corr()\n        \n        fig = go.Figure(data=go.Heatmap(\n            z=correlation_matrix.values,\n            x=correlation_matrix.columns,\n            y=correlation_matrix.index,\n            colorscale='RdBu',\n            zmid=0,\n            text=correlation_matrix.values.round(2),\n            texttemplate='%{text}',\n            textfont=dict(size=10)\n        ))\n        \n        fig.update_layout(\n            title=\"Feature Correlation Matrix\",\n            height=500\n        )\n        \n        return fig\n    \n    def create_confidence_distribution_chart(self, df: pd.DataFrame) -> go.Figure:\n        \"\"\"Create confidence score distribution chart\"\"\"\n        if df.empty:\n            return None\n        \n        fig = go.Figure()\n        \n        # Separate by detection result\n        human_scores = df[df['is_bot_detected'] == False]['confidence_score']\n        bot_scores = df[df['is_bot_detected'] == True]['confidence_score']\n        \n        if not human_scores.empty:\n            fig.add_trace(go.Histogram(\n                x=human_scores,\n                name='Human Predictions',\n                opacity=0.7,\n                nbinsx=20,\n                marker_color='#2ecc71'\n            ))\n        \n        if not bot_scores.empty:\n            fig.add_trace(go.Histogram(\n                x=bot_scores,\n                name='Bot Predictions',\n                opacity=0.7,\n                nbinsx=20,\n                marker_color='#e74c3c'\n            ))\n        \n        # Add threshold line\n        fig.add_vline(x=0.5, line_dash=\"dash\", line_color=\"black\", \n                      annotation_text=\"Decision Threshold\")\n        \n        fig.update_layout(\n            title=\"Confidence Score Distribution\",\n            xaxis_title=\"Confidence Score\",\n            yaxis_title=\"Frequency\",\n            height=400,\n            barmode='overlay'\n        )\n        \n        return fig\n    \n    def generate_insights(self, df: pd.DataFrame) -> List[str]:\n        \"\"\"Generate actionable insights from the data\"\"\"\n        insights = []\n        \n        if df.empty:\n            return [\"No data available for analysis\"]\n        \n        # Overall detection rate analysis\n        overall_detection_rate = len(df[df['is_bot_detected'] == True]) / len(df) * 100\n        \n        if overall_detection_rate > 80:\n            insights.append(f\"üö® Very high detection rate ({overall_detection_rate:.1f}%) - system may be oversensitive\")\n        elif overall_detection_rate < 10:\n            insights.append(f\"‚ö†Ô∏è Low detection rate ({overall_detection_rate:.1f}%) - system may need calibration\")\n        else:\n            insights.append(f\"‚úÖ Detection rate ({overall_detection_rate:.1f}%) appears balanced\")\n        \n        # Model performance comparison\n        if 'model_used' in df.columns and df['model_used'].nunique() > 1:\n            model_perf = df.groupby('model_used')['is_bot_detected'].mean() * 100\n            best_model = model_perf.idxmax()\n            worst_model = model_perf.idxmin()\n            \n            insights.append(f\"üèÜ Best performing model: {best_model} ({model_perf[best_model]:.1f}% detection rate)\")\n            \n            if model_perf[best_model] - model_perf[worst_model] > 20:\n                insights.append(f\"üìä Large variance between models ({model_perf[best_model] - model_perf[worst_model]:.1f}%) - consider ensemble\")\n        \n        # Real vs simulation analysis\n        real_df = df[df['source_type'] == 'real_user']\n        sim_df = df[df['source_type'] == 'simulation']\n        \n        if not real_df.empty and not sim_df.empty:\n            real_detection_rate = len(real_df[real_df['is_bot_detected'] == True]) / len(real_df) * 100\n            sim_detection_rate = len(sim_df[sim_df['is_bot_detected'] == True]) / len(sim_df) * 100\n            \n            if real_detection_rate > 15:\n                insights.append(f\"‚ö†Ô∏è High false positive rate on real users ({real_detection_rate:.1f}%)\")\n            \n            if sim_detection_rate < 50:\n                insights.append(f\"üé≠ Simulations are very realistic - only {sim_detection_rate:.1f}% detected\")\n            elif sim_detection_rate > 90:\n                insights.append(f\"ü§ñ Simulations are easily detected ({sim_detection_rate:.1f}%) - may need refinement\")\n        \n        # Feature analysis\n        feature_cols = ['avg_mouse_speed', 'avg_typing_speed', 'tab_switch_rate', \n                       'mouse_click_rate', 'keyboard_error_rate']\n        \n        available_features = [col for col in feature_cols if col in df.columns]\n        \n        if available_features:\n            # Find most discriminative features\n            feature_importance = {}\n            \n            for feature in available_features:\n                human_values = df[df['is_bot_detected'] == False][feature]\n                bot_values = df[df['is_bot_detected'] == True][feature]\n                \n                if not human_values.empty and not bot_values.empty:\n                    # Calculate separation (simplified)\n                    separation = abs(human_values.mean() - bot_values.mean()) / (human_values.std() + bot_values.std() + 1e-6)\n                    feature_importance[feature] = separation\n            \n            if feature_importance:\n                most_important = max(feature_importance.keys(), key=lambda k: feature_importance[k])\n                insights.append(f\"üéØ Most discriminative feature: {most_important.replace('_', ' ').title()}\")\n        \n        # Temporal analysis\n        df['hour'] = df['timestamp'].dt.hour\n        hourly_detection = df.groupby('hour')['is_bot_detected'].mean() * 100\n        \n        peak_hour = hourly_detection.idxmax()\n        low_hour = hourly_detection.idxmin()\n        \n        if hourly_detection[peak_hour] - hourly_detection[low_hour] > 30:\n            insights.append(f\"‚è∞ Detection rates vary significantly by time - peak at {peak_hour}:00 ({hourly_detection[peak_hour]:.1f}%)\")\n        \n        return insights
    
    def show_overview_section(self, df: pd.DataFrame):\n        \"\"\"Show overview metrics section\"\"\"\n        st.header(\"üìä System Overview\")\n        \n        metrics = self.create_overview_metrics(df)\n        \n        col1, col2, col3, col4 = st.columns(4)\n        \n        with col1:\n            st.metric(\n                \"Total Events\",\n                f\"{metrics['total_events']:,}\",\n                delta=None\n            )\n        \n        with col2:\n            st.metric(\n                \"Bot Detections\",\n                f\"{metrics['bot_detections']:,}\",\n                delta=f\"{metrics['detection_rate']:.1f}% rate\"\n            )\n        \n        with col3:\n            st.metric(\n                \"Average Confidence\",\n                f\"{metrics['avg_confidence']:.3f}\",\n                delta=None\n            )\n        \n        with col4:\n            st.metric(\n                \"Unique Users\",\n                f\"{metrics['unique_users']:,}\",\n                delta=None\n            )\n        \n        # Source type breakdown\n        st.subheader(\"üìã Data Source Breakdown\")\n        \n        source_col1, source_col2, source_col3 = st.columns(3)\n        \n        with source_col1:\n            st.metric(\n                \"Real Users\", \n                f\"{metrics['real_user_events']:,}\",\n                delta=f\"{metrics['real_user_events'] / max(1, metrics['total_events']) * 100:.1f}%\"\n            )\n        \n        with source_col2:\n            st.metric(\n                \"Simulations\",\n                f\"{metrics['simulation_events']:,}\",\n                delta=f\"{metrics['simulation_events'] / max(1, metrics['total_events']) * 100:.1f}%\"\n            )\n        \n        with source_col3:\n            st.metric(\n                \"Dataset Replays\",\n                f\"{metrics['dataset_replay_events']:,}\",\n                delta=f\"{metrics['dataset_replay_events'] / max(1, metrics['total_events']) * 100:.1f}%\"\n            )\n    \n    def show_detection_analysis_section(self, df: pd.DataFrame):\n        \"\"\"Show detection analysis charts\"\"\"\n        st.header(\"üîç Detection Analysis\")\n        \n        if df.empty:\n            st.info(\"No detection data available for analysis\")\n            return\n        \n        # Timeline chart\n        timeline_chart = self.create_detection_timeline_chart(df)\n        if timeline_chart:\n            st.plotly_chart(timeline_chart, use_container_width=True)\n        \n        col1, col2 = st.columns(2)\n        \n        with col1:\n            # Model performance chart\n            model_chart = self.create_model_performance_chart(df)\n            if model_chart:\n                st.plotly_chart(model_chart, use_container_width=True)\n        \n        with col2:\n            # Confidence distribution chart\n            confidence_chart = self.create_confidence_distribution_chart(df)\n            if confidence_chart:\n                st.plotly_chart(confidence_chart, use_container_width=True)\n    \n    def show_simulation_analysis_section(self, df: pd.DataFrame):\n        \"\"\"Show simulation-specific analysis\"\"\"\n        st.header(\"üß™ Simulation Analysis\")\n        \n        sim_df = df[df['source_type'] == 'simulation']\n        \n        if sim_df.empty:\n            st.info(\"No simulation data available for analysis\")\n            return\n        \n        # Profile analysis chart\n        profile_chart = self.create_profile_analysis_chart(df)\n        if profile_chart:\n            st.plotly_chart(profile_chart, use_container_width=True)\n        \n        # Simulation mode breakdown\n        if 'simulation_mode' in sim_df.columns:\n            st.subheader(\"üéõÔ∏è Simulation Mode Performance\")\n            \n            mode_stats = sim_df.groupby('simulation_mode').agg({\n                'is_bot_detected': ['count', 'sum'],\n                'confidence_score': 'mean'\n            }).reset_index()\n            \n            mode_stats.columns = ['mode', 'total_events', 'detections', 'avg_confidence']\n            mode_stats['detection_rate'] = mode_stats['detections'] / mode_stats['total_events'] * 100\n            \n            # Display as table\n            st.dataframe(\n                mode_stats[['mode', 'total_events', 'detections', 'detection_rate', 'avg_confidence']],\n                column_config={\n                    'mode': 'Simulation Mode',\n                    'total_events': 'Total Events',\n                    'detections': 'Bot Detections',\n                    'detection_rate': st.column_config.NumberColumn('Detection Rate (%)', format=\"%.1f\"),\n                    'avg_confidence': st.column_config.NumberColumn('Avg Confidence', format=\"%.3f\")\n                },\n                use_container_width=True\n            )\n    \n    def show_insights_section(self, df: pd.DataFrame):\n        \"\"\"Show insights and recommendations\"\"\"\n        st.header(\"üí° Insights & Recommendations\")\n        \n        insights = self.generate_insights(df)\n        \n        for insight in insights:\n            if \"üö®\" in insight or \"‚ö†Ô∏è\" in insight:\n                st.warning(insight)\n            elif \"‚úÖ\" in insight or \"üèÜ\" in insight:\n                st.success(insight)\n            else:\n                st.info(insight)\n        \n        # System health assessment\n        dashboard_data = self.feedback_system.generate_performance_dashboard()\n        system_health = dashboard_data['system_health']\n        \n        st.subheader(\"ü©∫ System Health Assessment\")\n        \n        health_col1, health_col2 = st.columns(2)\n        \n        with health_col1:\n            # Health score with color coding\n            score = system_health['score']\n            if score >= 85:\n                st.success(f\"Health Score: {score}/100 ({system_health['status']})\")\n            elif score >= 70:\n                st.info(f\"Health Score: {score}/100 ({system_health['status']})\")\n            else:\n                st.warning(f\"Health Score: {score}/100 ({system_health['status']})\")\n        \n        with health_col2:\n            if system_health['issues']:\n                st.error(\"üö® Critical Issues:\")\n                for issue in system_health['issues']:\n                    st.write(f\"‚Ä¢ {issue}\")\n            \n            if system_health['warnings']:\n                st.warning(\"‚ö†Ô∏è Warnings:\")\n                for warning in system_health['warnings']:\n                    st.write(f\"‚Ä¢ {warning}\")\n    \n    def show_export_section(self, df: pd.DataFrame):\n        \"\"\"Show data export options\"\"\"\n        st.header(\"üì§ Export & Reports\")\n        \n        col1, col2, col3 = st.columns(3)\n        \n        with col1:\n            if st.button(\"üìä Export Analysis Report\"):\n                try:\n                    report_file = self.feedback_system.export_analysis_report()\n                    if report_file:\n                        st.success(f\"Report exported: {report_file}\")\n                except Exception as e:\n                    st.error(f\"Export failed: {e}\")\n        \n        with col2:\n            if st.button(\"üìã Download Detection Data\"):\n                if not df.empty:\n                    csv = df.to_csv(index=False)\n                    st.download_button(\n                        label=\"Download CSV\",\n                        data=csv,\n                        file_name=f\"detection_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n                        mime=\"text/csv\"\n                    )\n                else:\n                    st.warning(\"No data to export\")\n        \n        with col3:\n            if st.button(\"üîÑ Refresh Data\"):\n                st.rerun()\n    \n    def show_dashboard(self, days: int = 7):\n        \"\"\"Show complete analytics dashboard\"\"\"\n        st.title(\"üìà AuthAI Analytics Dashboard\")\n        st.markdown(f\"**Analysis Period:** Last {days} days\")\n        \n        # Load data\n        with st.spinner(\"Loading detection data...\"):\n            df = self.load_detection_data(days)\n        \n        if df.empty:\n            st.warning(\"No detection data found. Run some tests first!\")\n            \n            # Show sample data info\n            st.info(\"üí° **To get started:** Run some behavior simulations or real user sessions to generate analytics data.\")\n            return\n        \n        # Show sections\n        self.show_overview_section(df)\n        \n        st.markdown(\"---\")\n        self.show_detection_analysis_section(df)\n        \n        st.markdown(\"---\")\n        self.show_simulation_analysis_section(df)\n        \n        st.markdown(\"---\")\n        \n        # Feature correlation section\n        st.header(\"üîó Feature Analysis\")\n        correlation_chart = self.create_feature_correlation_matrix(df)\n        if correlation_chart:\n            st.plotly_chart(correlation_chart, use_container_width=True)\n        else:\n            st.info(\"Insufficient data for feature correlation analysis\")\n        \n        st.markdown(\"---\")\n        self.show_insights_section(df)\n        \n        st.markdown(\"---\")\n        self.show_export_section(df)\n        \n        # Auto-refresh option\n        st.sidebar.markdown(\"---\")\n        st.sidebar.subheader(\"üìà Analytics Options\")\n        \n        analysis_days = st.sidebar.slider(\n            \"Analysis Period (days):\",\n            min_value=1,\n            max_value=90,\n            value=days,\n            key=\"analysis_days\"\n        )\n        \n        if analysis_days != days:\n            st.rerun()\n        \n        auto_refresh = st.sidebar.checkbox(\"Auto-refresh every 30 seconds\", value=False)\n        \n        if auto_refresh:\n            time.sleep(30)\n            st.rerun()

# Standalone analytics page function
def show_analytics_page():\n    \"\"\"Show analytics dashboard as a standalone page\"\"\"\n    dashboard = AnalyticsDashboard()\n    dashboard.show_dashboard()\n\n# Example usage\nif __name__ == \"__main__\":\n    # Configure page\n    st.set_page_config(\n        page_title=\"AuthAI Analytics\",\n        page_icon=\"üìà\",\n        layout=\"wide\"\n    )\n    \n    show_analytics_page()
